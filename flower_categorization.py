# -*- coding: utf-8 -*-
"""Flower_categorization.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1nJy82gTrb4McYELRUZrynn1pEtByjJ16
"""

import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.datasets import load_iris
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn import preprocessing
from sklearn.neighbors import KNeighborsClassifier
from sklearn.svm import SVC
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, confusion_matrix, classification_report

# Load the Iris dataset
iris = load_iris()
df = pd.DataFrame(data=iris.data, columns=iris.feature_names)
df['target'] = iris.target # Add flower types (0, 1, 2)

# Display the first 5 rows of data
print("Raw data:")
print(df.head())

# Basic information about the data
print("Data information")
print(df.info())

# Descriptive statistics of data
print("data description:")
print(df.describe())

# Drawing relationship diagrams between attributes
sns.pairplot(df, hue='target', palette='viridis')
plt.show()

if df.isnull().sum().any():
    print("Missing values detected:")
    print(df.isnull().sum())
else:
    print("No missing values found.")

plt.scatter(principalDf['principal component 1'], principalDf['principal component 2'], c=df['target'])
plt.xlabel('Principal Component 1')
plt.ylabel('Principal Component 2')
plt.show()

# Prepare the data
x = df.drop('target', axis=1) # Features (petal and sepal length and width)
y = df['target'] # species (target)

# Split the data into training (80%) and testing (20%)
x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)

# Standardization to improve the performance of the model
scaler = StandardScaler()
x_train = scaler.fit_transform(x_train)
x_test = scaler.transform(x_test)

# Step 2: Train the K-Nearest Neighbors model
model = KNeighborsClassifier(n_neighbors=3)
model.fit(x_train, y_train)

# Step 3: Prediction and model evaluation
y_pred = model.predict(x_test)
accuracy = accuracy_score(y_test, y_pred)
print("Model accuracy on test data: {:.2f}%".format(accuracy * 100))

# Display the Confusion Matrix
conf_matrix = confusion_matrix(y_test, y_pred)
print(conf_matrix)
print(classification_report(y_test, y_pred))

plt.figure(figsize=(6, 5))
sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues',
            xticklabels=iris.target_names, yticklabels=iris.target_names)
plt.title('Confusion matrix for categorizing flowers')
plt.xlabel('prediction')
plt.ylabel('actual')
plt.tight_layout()
plt.savefig('confusion_matrix.png')
plt.show()

# Step 4: Visualize the data (example: distribution of petal length by species)
df['species'] = df['target'].map({0: 'setosa', 1: 'versicolor', 2: 'virginica'})
plt.figure(figsize=(8, 5))
sns.scatterplot(data=df, x='petal length (cm)', y='petal width (cm)', hue='species', style='species', s=100)
plt.title('Distribution of petal length and width by flower species')
plt.xlabel('Petal length (cm)')
plt.ylabel('Petal width (cm)')
plt.tight_layout()
plt.savefig('petal_scatter.png')
plt.show()

model=SVC()
model.fit(x_train, y_train)

y_pred=model.predict(x_test)
accuracy=accuracy_score(y_test, y_pred)
print("Model accuracy on test data: {:.2f}%".format(accuracy * 100))

model=LogisticRegression()
model.fit(x_train, y_train)

y_pred=model.predict(x_test)
accuracy=accuracy_score(y_test, y_pred)
print("Model accuracy on test data: {:.2f}%".format(accuracy * 100))

models = {
    'KNN': KNeighborsClassifier(),
    'SVM': SVC(),
    'Logistic Regression': LogisticRegression()
}

for name, model in models.items():
    model.fit(x_train, y_train)
    print(f"{name} accuracy: {model.score(x_test, y_test):.2f}")